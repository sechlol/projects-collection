{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "  # Introduction to Deep Learning (LDA-T3114)\n",
    "  ## Code for Assignment 1: Sentiment Classification on a Feed-Forward Neural Network\n",
    "\n",
    "   Group ID: **GradientDescendants**\n",
    "   Group Members:\n",
    "   * Cardin Christian\n",
    "   * Nieminen Harri\n",
    "   * Zetterman Elina\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTgWmDBDWutR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from data_semeval import *\n",
    "from paths import data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJp3BkaHWw74"
   },
   "outputs": [],
   "source": [
    "#--- hyperparameters ---\n",
    "\n",
    "N_CLASSES = len(LABEL_INDICES)\n",
    "N_EPOCHS = 20\n",
    "LEARNING_RATE = 0.02\n",
    "BATCH_SIZE = 20\n",
    "REPORT_EVERY = 1\n",
    "IS_VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gvAm0fHW2lH"
   },
   "outputs": [],
   "source": [
    "def make_bow(tweet, indices):\n",
    "    feature_ids = list(indices[tok] for tok in tweet['BODY'] if tok in indices)\n",
    "    bow_vec = torch.zeros(len(indices))\n",
    "    bow_vec[feature_ids] = 1\n",
    "    return bow_vec.view(1, -1)\n",
    "\n",
    "def generate_bow_representations(data):\n",
    "    vocab = set(token for tweet in data['training'] for token in tweet['BODY'])\n",
    "    vocab_size = len(vocab) \n",
    "    indices = {w:i for i, w in enumerate(vocab)}\n",
    "  \n",
    "    for split in [\"training\",\"development.input\",\"development.gold\",\n",
    "                  \"test.input\",\"test.gold\"]:\n",
    "        for tweet in data[split]:\n",
    "            tweet['BOW'] = make_bow(tweet,indices)\n",
    "\n",
    "    return indices, vocab_size\n",
    "\n",
    "# Convert string label to pytorch format.\n",
    "def label_to_idx(label):\n",
    "    return torch.LongTensor([LABEL_INDICES[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iiXMR3LAW_GC"
   },
   "outputs": [],
   "source": [
    "#--- data loading ---\n",
    "data = read_semeval_datasets(data_dir)\n",
    "indices, vocab_size = generate_bow_representations(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size: int, n_classes: int, hidden_layers: int, layer_size: int):\n",
    "        \"\"\"\n",
    "        hidden_layers: number of hidden layers in the network\n",
    "        layer_size: number of neurons in each hidden layer\n",
    "        \"\"\"\n",
    "        super(FFNN, self).__init__()\n",
    "        self.in_layer = nn.Linear(in_features=input_size, out_features=layer_size)\n",
    "\n",
    "        # Note: the range is up to (hidden_layers - 1) because the first layer is also a hidden layer\n",
    "        self.hidden_layers = [nn.Linear(in_features=layer_size, out_features=layer_size) for _ in range(hidden_layers - 1)]\n",
    "        self.out_layer = nn.Linear(in_features=layer_size, out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Uses ReLu as nonlinear function for hidden layers\n",
    "        result = torch.relu(self.in_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            result = torch.relu(layer(result))\n",
    "\n",
    "        # Important: need to specify the dimension over which to compute the softmax.\n",
    "        return F.log_softmax(self.out_layer(result), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0k4wWf8XCMr"
   },
   "outputs": [],
   "source": [
    "model = FFNN(vocab_size, N_CLASSES, hidden_layers=2, layer_size=15)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAq0EdZIXJo5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.0073\n",
      "epoch: 2, loss: 0.9878\n",
      "epoch: 3, loss: 0.9799\n",
      "epoch: 4, loss: 0.9625\n",
      "epoch: 5, loss: 0.9341\n",
      "epoch: 6, loss: 0.9008\n",
      "epoch: 7, loss: 0.8686\n",
      "epoch: 8, loss: 0.8351\n",
      "epoch: 9, loss: 0.8019\n",
      "epoch: 10, loss: 0.7670\n",
      "epoch: 11, loss: 0.7324\n",
      "epoch: 12, loss: 0.6996\n",
      "epoch: 13, loss: 0.6653\n",
      "epoch: 14, loss: 0.6342\n",
      "epoch: 15, loss: 0.6033\n",
      "epoch: 16, loss: 0.5719\n",
      "epoch: 17, loss: 0.5424\n",
      "epoch: 18, loss: 0.5134\n",
      "epoch: 19, loss: 0.4851\n",
      "epoch: 20, loss: 0.4572\n"
     ]
    }
   ],
   "source": [
    "#--- training ---\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0\n",
    "    #shuffle the datasets per every epoch\n",
    "    random.shuffle(data['training'])\n",
    "\n",
    "    for i in range(int(len(data['training'])/BATCH_SIZE)):\n",
    "        minibatch = data['training'][i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        \n",
    "        # run all inputs in the batch through the model to get the predictions\n",
    "        # optimize loss function with batch predictions and actuals\n",
    "        pred = model(torch.vstack([tweet[\"BOW\"] for tweet in minibatch]))\n",
    "        act = torch.tensor([label_to_idx(tweet[\"SENTIMENT\"]) for tweet in minibatch])  \n",
    "            \n",
    "        # loss calculation and optimisation for batch\n",
    "        loss = loss_function(pred, act)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update total loss for epoch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if ((epoch+1) % REPORT_EVERY) == 0:\n",
    "        print('epoch: %d, loss: %.4f' % (epoch+1, total_loss*BATCH_SIZE/len(data['training'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 3055/4633 65.94%\n"
     ]
    }
   ],
   "source": [
    "#--- test ---\n",
    "correct = 0\n",
    "test_len = len(data['test.gold'])\n",
    "with torch.no_grad():\n",
    "    for tweet in data['test.gold']:\n",
    "        gold_class = label_to_idx(tweet['SENTIMENT'])\n",
    "        predicted = model(tweet[\"BOW\"]).argmax()\n",
    "\n",
    "        if predicted == gold_class:\n",
    "            correct += 1\n",
    "\n",
    "        if IS_VERBOSE:\n",
    "            print('TEST DATA: %s, GOLD LABEL: %s, GOLD CLASS %d, OUTPUT: %d' %\n",
    "                 (' '.join(tweet['BODY'][:-1]), tweet['SENTIMENT'], gold_class, predicted))\n",
    "\n",
    "    print(f\"Test Accuracy: {correct}/{test_len} {correct/test_len:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_hw1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
